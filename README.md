# Coro-Plus AI

## Syst√®me IA pour l'am√©lioration du coroscanner en imagerie coronaire

![Version](https://img.shields.io/badge/version-0.1.0-blue)
![Status](https://img.shields.io/badge/status-MVP-green)
![License](https://img.shields.io/badge/license-Academic-orange)

### üìã Pr√©sentation du projet

**Coro-Plus AI** est un prototype acad√©mique d'Intelligence Artificielle con√ßu pour am√©liorer les images de coroscanner en imagerie coronaire. D√©velopp√© dans le cadre d'un projet de Licence Professionnelle 3√®me ann√©e en Manipulateur en Imagerie M√©dicale √† l'INFSPM Oran par **Abidine**.

#### Contexte m√©dical

Le coroscanner (CT coronaire) est un examen tr√®s performant pour l'anatomie coronaire mais pr√©sente plusieurs inconv√©nients :
- Dose de rayons X √©lev√©e
- N√©cessit√© de produit de contraste iod√©
- Pr√©sence de bruit et d'art√©facts dans les images
- Temps de post-traitement important
- Manque d'informations fonctionnelles

**Coro-Plus AI** vise √† am√©liorer ces aspects gr√¢ce √† l'Intelligence Artificielle.

---

## üéØ Objectifs du syst√®me

Le prototype offre deux modules principaux :

### Module A - D√©bruitage et am√©lioration d'image (Prioritaire)
- R√©duction du bruit dans les images de coroscanner
- Am√©lioration du contraste pour une meilleure lisibilit√©
- Pr√©servation des d√©tails anatomiques importants
- Potentiel de r√©duction de dose de rayonnement

### Module B - Segmentation coronaire (D√©monstratif)
- D√©tection basique des structures vasculaires
- Mise en √©vidence des art√®res coronaires principales
- Base pour analyse quantitative future

### Module C - G√©n√©ration de rapport
- Rapport automatique avec m√©triques quantitatives
- Temps de traitement
- Pourcentage de r√©duction du bruit
- Am√©lioration du contraste

---

## üöÄ Installation et utilisation

### Pr√©requis

- Node.js 20+ install√©
- npm ou pnpm

### Installation

```bash
# Cloner le d√©p√¥t
git clone <repository-url>
cd coro-plus-ai

# Installer les d√©pendances
npm install

# Lancer le serveur de d√©veloppement
npm run dev
```

### Utilisation

1. Ouvrir le navigateur √† `http://localhost:3000`
2. S√©lectionner un module (D√©bruitage ou Segmentation)
3. Charger une image de coroscanner (PNG, JPEG)
4. Cliquer sur "Appliquer le traitement"
5. Visualiser les r√©sultats avant/apr√®s
6. T√©l√©charger les images trait√©es
7. G√©n√©rer un rapport d'analyse

### Format des images

- **Format support√© actuellement** : PNG, JPEG
- **Format DICOM** : Convertir en PNG/JPEG avant utilisation
- **R√©solution recommand√©e** : 512√ó512 ou 256√ó256 pixels
- **Type d'image** : Images de coroscanner en niveaux de gris ou couleur

---

## üèóÔ∏è Architecture technique

### Stack technologique

- **Frontend** : Next.js 16 (App Router) + React 19
- **Langage** : TypeScript
- **Styling** : Tailwind CSS 4
- **Icons** : Lucide React
- **Traitement d'image** : Canvas API (Browser native)

### Architecture de traitement

#### Module A - D√©bruitage
```
Image d'entr√©e
    ‚Üì
Filtre bilat√©ral
    ‚îú‚îÄ Pr√©servation des contours (spatial weight)
    ‚îî‚îÄ Lissage adaptatif (range weight)
    ‚Üì
Am√©lioration du contraste
    ‚îî‚îÄ Ajustement adaptatif autour du point m√©dian
    ‚Üì
Calcul des m√©triques
    ‚îú‚îÄ Variance du bruit
    ‚îî‚îÄ Plage de contraste
    ‚Üì
Image am√©lior√©e
```

**Algorithmes utilis√©s** :
- **Filtre bilat√©ral** : R√©duit le bruit tout en pr√©servant les contours
  - Param√®tres : œÉ_space = 5.0, œÉ_range = 30.0, kernel radius = 3
- **Enhancement de contraste** : Am√©lioration multiplicative autour du point m√©dian
  - Facteur : 1.3 (ajustable)

#### Module B - Segmentation (version d√©monstrative)
```
Image d'entr√©e
    ‚Üì
Conversion en niveaux de gris
    ‚Üì
Seuillage d'intensit√©
    ‚îî‚îÄ D√©tection des zones haute densit√© (> 180)
    ‚Üì
Coloration des structures d√©tect√©es
    ‚Üì
Image segment√©e
```

### Structure du code

```
coro-plus-ai/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx          # Layout principal avec m√©tadonn√©es
‚îÇ   ‚îú‚îÄ‚îÄ page.tsx            # Interface utilisateur principale
‚îÇ   ‚îî‚îÄ‚îÄ globals.css         # Styles globaux
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ imageProcessing.ts  # Algorithmes de traitement d'image
‚îú‚îÄ‚îÄ public/                 # Assets statiques
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ README.md
```

---

## üìä M√©triques et √©valuation

### M√©triques calcul√©es

1. **R√©duction du bruit** : Bas√©e sur la variance des pixels
   - Formule : `(variance_original - variance_processed) / variance_original * 100`

2. **Am√©lioration du contraste** : Bas√©e sur la plage dynamique
   - Formule : `(contrast_processed - contrast_original) / contrast_original * 100`

3. **Temps de traitement** : Mesure de performance en millisecondes

### R√©sultats attendus

| M√©trique | Valeur typique | Objectif |
|----------|---------------|----------|
| R√©duction du bruit | 15-30% | > 20% |
| Am√©lioration contraste | 20-40% | > 15% |
| Temps de traitement | 100-500ms | < 1000ms |

---

## üî¨ Int√©gration avec mod√®les Deep Learning

### Pour passer en production

Le syst√®me actuel utilise des algorithmes classiques de traitement d'image pour la d√©monstration. Pour une application clinique, il est recommand√© d'int√©grer des mod√®les de deep learning :

#### Architecture recommand√©e pour Module A (D√©bruitage)

```python
# Autoencodeur pour d√©bruitage
class DenoisingAutoencoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),
            nn.ReLU(),
            nn.Conv2d(32, 1, kernel_size=3, padding=1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x
```

#### Architecture recommand√©e pour Module B (Segmentation)

```python
# U-Net pour segmentation coronaires
class CoronaryUNet(nn.Module):
    def __init__(self):
        super().__init__()
        # Encoder
        self.enc1 = self.conv_block(1, 64)
        self.enc2 = self.conv_block(64, 128)
        self.enc3 = self.conv_block(128, 256)
        
        # Bottleneck
        self.bottleneck = self.conv_block(256, 512)
        
        # Decoder
        self.dec3 = self.upconv_block(512, 256)
        self.dec2 = self.upconv_block(256, 128)
        self.dec1 = self.upconv_block(128, 64)
        
        self.out = nn.Conv2d(64, 1, kernel_size=1)
    
    def conv_block(self, in_ch, out_ch):
        return nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )
```

### Datasets recommand√©s pour entra√Ænement

- **ASOCA** (Automated Segmentation of Coronary Arteries)
- **CA-500** (Coronary Artery 500)
- Donn√©es synth√©tiques g√©n√©r√©es avec bruit ajout√©

### Int√©gration dans Next.js

Option 1 : **API Backend Python**
```typescript
// Cr√©er une API route Next.js
// app/api/denoise/route.ts
export async function POST(request: Request) {
  const formData = await request.formData();
  const image = formData.get('image');
  
  // Appeler API Python
  const response = await fetch('http://localhost:5000/denoise', {
    method: 'POST',
    body: formData
  });
  
  return response;
}
```

Option 2 : **TensorFlow.js (in-browser)**
```typescript
import * as tf from '@tensorflow/tfjs';

async function loadModel() {
  const model = await tf.loadLayersModel('/models/denoising/model.json');
  return model;
}

async function denoise(imageData: ImageData) {
  const model = await loadModel();
  const tensor = tf.browser.fromPixels(imageData, 1);
  const normalized = tensor.div(255.0);
  const batched = normalized.expandDims(0);
  const prediction = model.predict(batched);
  return prediction;
}
```

---

## ‚ö†Ô∏è Limitations et avertissements

### Limitations actuelles

1. **Usage acad√©mique uniquement** : Ce prototype n'est pas valid√© cliniquement
2. **Pas de support DICOM natif** : Conversion manuelle n√©cessaire
3. **Algorithmes simplifi√©s** : Les algorithmes actuels sont d√©monstratifs
4. **Pas de validation m√©dicale** : Non test√© sur des cas cliniques r√©els
5. **Segmentation basique** : Module B utilise des seuils simples

### Avertissements importants

‚ö†Ô∏è **Ce syst√®me ne doit PAS √™tre utilis√© pour :**
- Le diagnostic m√©dical clinique
- La prise de d√©cision th√©rapeutique
- Le remplacement de l'expertise m√©dicale

‚úÖ **Ce syst√®me peut √™tre utilis√© pour :**
- D√©monstration p√©dagogique
- Recherche acad√©mique
- Exploration de concepts IA en imagerie m√©dicale
- Base pour d√©veloppement ult√©rieur

---

## üìà D√©veloppements futurs

### Roadmap propos√©e

#### Phase 1 - MVP actuel ‚úÖ
- [x] Interface web fonctionnelle
- [x] Module A : D√©bruitage basique
- [x] Module B : Segmentation d√©monstrative
- [x] G√©n√©ration de rapport

#### Phase 2 - Am√©lioration IA
- [ ] Int√©gration mod√®le PyTorch/TensorFlow
- [ ] Entra√Ænement sur dataset ASOCA
- [ ] Support DICOM natif
- [ ] Optimisation des performances

#### Phase 3 - Fonctionnalit√©s avanc√©es
- [ ] Analyse quantitative des st√©noses
- [ ] Calcul de la FFR (Fractional Flow Reserve)
- [ ] Visualisation 3D des coronaires
- [ ] Export DICOM avec m√©tadonn√©es

#### Phase 4 - Validation clinique
- [ ] Tests sur cas r√©els
- [ ] Validation par radiologues/cardiologues
- [ ] √âtude comparative avec m√©thodes standard
- [ ] Publication scientifique

---

## ü§ù Contribution et collaboration

### Contributeurs

- **Abidine** - √âtudiant L3, Manipulateur en Imagerie M√©dicale, INFSPM Oran
- D√©velopp√© avec le support d'outils d'IA

### Comment contribuer

Pour contribuer √† ce projet acad√©mique :

1. Fork le repository
2. Cr√©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

### Contact

Pour questions ou collaborations :
- Institution : INFSPM Oran
- Projet : Coro-Plus AI
- Type : Projet acad√©mique L3

---

## üìö R√©f√©rences

### Articles scientifiques pertinents

1. **Deep Learning for Image Denoising:**
   - Zhang et al. (2017). "Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising"

2. **Medical Image Segmentation:**
   - Ronneberger et al. (2015). "U-Net: Convolutional Networks for Biomedical Image Segmentation"

3. **Coronary CT Analysis:**
   - Lessmann et al. (2019). "Automatic Calcium Scoring in Low-Dose Chest CT Using Deep Neural Networks"

### Ressources techniques

- [Next.js Documentation](https://nextjs.org/docs)
- [TensorFlow.js](https://www.tensorflow.org/js)
- [PyTorch](https://pytorch.org/)
- [DICOM Standard](https://www.dicomstandard.org/)

---

## üìÑ License

Ce projet est d√©velopp√© √† des fins acad√©miques dans le cadre d'un projet de fin d'√©tudes. 

**Utilisation acad√©mique uniquement - Pas d'usage clinique**

---

## üôè Remerciements

- INFSPM Oran - Institut National de Formation Sup√©rieure Param√©dicale
- Encadrants acad√©miques
- Communaut√© open-source (Next.js, React, TensorFlow)

---

**Version** : 0.1.0 (MVP)  
**Date** : D√©cembre 2024  
**Statut** : Prototype acad√©mique  

---

*Coro-Plus AI - Am√©liorer l'imagerie coronaire par l'Intelligence Artificielle*
